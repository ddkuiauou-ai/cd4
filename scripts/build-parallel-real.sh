#!/bin/bash
# CD3 Project - TRUE Parallel Build Script with Memory Optimization

echo "ğŸš€ Starting TRUE parallel SSG builds with memory optimization..."

CHUNK_SIZE=${CHUNK_SIZE:-400}  # 2ì½”ì–´ 8GB í™˜ê²½ìš© ì†ë„ ìµœì í™” ì²­í¬ í¬ê¸°
TOTAL_CHUNKS=${TOTAL_CHUNKS:-6}  # ì ì ˆí•œ ìˆ˜ì˜ ì²­í¬ë¡œ ë‚˜ëˆ„ê¸°
MAX_PARALLEL=${MAX_PARALLEL:-2}  # 2ì½”ì–´ í™œìš©í•˜ì—¬ ì†ë„ í–¥ìƒ

echo "ğŸ“Š Configuration:"
echo "   - Chunk size: $CHUNK_SIZE securities per chunk"
echo "   - Total chunks: $TOTAL_CHUNKS"
echo "   - Max parallel processes: $MAX_PARALLEL"
echo "   - Running builds in batches for memory efficiency!"

# ë””ìŠ¤í¬ ì‚¬ìš©ëŸ‰ í™•ì¸
echo "ğŸ“Š Initial disk usage:"
df -h

# Clean up any existing chunk outputs
echo "ğŸ§¹ Cleaning up previous build artifacts..."
rm -rf out-chunk-*
rm -rf out
rm -rf .next 2>/dev/null || true

# Ensure cache directories exist to prevent webpack warnings
echo "ğŸ“ Ensuring cache directories exist..."
mkdir -p .next/cache/webpack/client-production
mkdir -p .next/cache/webpack/server-production

# Launch chunks in batches for memory efficiency
echo "ğŸ“‹ Processing chunks in batches of $MAX_PARALLEL..."

for ((start_idx=0; start_idx<TOTAL_CHUNKS; start_idx+=MAX_PARALLEL)); do
    end_idx=$((start_idx + MAX_PARALLEL))
    if [ $end_idx -gt $TOTAL_CHUNKS ]; then
        end_idx=$TOTAL_CHUNKS
    fi

    echo ""
    echo "ğŸ”„ Processing batch: chunks $((start_idx+1))-$end_idx"

    # Launch current batch in background
    batch_pids=()
    for i in $(seq $start_idx $((end_idx-1))); do
        echo "ğŸ”¨ Starting chunk $((i+1))/$TOTAL_CHUNKS..."
        (
            export BUILD_CHUNK_INDEX=$i
            export BUILD_CHUNK_TOTAL=$TOTAL_CHUNKS
            export BUILD_CHUNK_SIZE=$CHUNK_SIZE
            export NEXT_BUILD_DIR="out-chunk-$i"
            export BUILD_OUTPUT_DIR="out-chunk-$i"
            export NODE_OPTIONS="--max-old-space-size=2048"  # 8GB í™˜ê²½ì—ì„œ 2GB í• ë‹¹ìœ¼ë¡œ ì•ˆì •ì„± ê·¹ëŒ€í™”

            echo "  ğŸ“¦ Chunk $((i+1)) building to: out-chunk-$i"

            # ë””ìŠ¤í¬ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§
            echo "  ğŸ’¾ Disk usage before build:"
            df -h | grep -E "(Filesystem|overlay)"

            pnpm build:ssg

            if [ $? -eq 0 ]; then
                echo "  âœ… Chunk $((i+1)) completed!"

                # ì™„ë£Œëœ ì²­í¬ì˜ ìºì‹œ ì •ë¦¬ (ë©”ëª¨ë¦¬ ì ˆì•½)
                rm -rf .next-${i} 2>/dev/null || true

                echo "  ğŸ’¾ Disk usage after cleanup:"
                df -h | grep -E "(Filesystem|overlay)"
            else
                echo "  âŒ Chunk $((i+1)) failed!"
                exit 1
            fi
        ) &
        batch_pids+=($!)
    done

    echo "â³ Waiting for batch to complete..."
    # Wait for current batch to complete
    for pid in "${batch_pids[@]}"; do
        if ! wait $pid; then
            echo "ğŸ’¥ Batch failed! Exiting..."
            exit 1
        fi
    done

    echo "âœ… Batch completed successfully!"

    # ë°°ì¹˜ ì™„ë£Œ í›„ ë©”ëª¨ë¦¬ ì •ë¦¬
    echo "ğŸ§¹ Cleaning up memory and temporary files..."
    sync
    echo 3 > /proc/sys/vm/drop_caches 2>/dev/null || true
done

echo ""
echo "â³ Waiting for all $TOTAL_CHUNKS parallel builds to complete..."

# Wait for all background processes
failed=0
for i in "${!pids[@]}"; do
    pid=${pids[$i]}
    if wait $pid; then
        echo "âœ… Chunk $((i+1)) finished successfully"
    else
        echo "âŒ Chunk $((i+1)) failed!"
        failed=1
    fi
done

if [ $failed -eq 1 ]; then
    echo "ğŸ’¥ Some chunks failed! Exiting..."
    exit 1
fi

echo ""
echo "ğŸ”— Merging all chunk outputs into final 'out' directory..."

# ë””ìŠ¤í¬ ì‚¬ìš©ëŸ‰ í™•ì¸
echo "ğŸ’¾ Disk usage before merge:"
df -h

# Create main output directory
mkdir -p out

# Merge all chunk directories (ë©”ëª¨ë¦¬ íš¨ìœ¨ì ìœ¼ë¡œ)
for i in $(seq 0 $((TOTAL_CHUNKS-1))); do
    if [ -d "out-chunk-$i" ]; then
        echo "  ğŸ“ Merging out-chunk-$i..."

        # ëŒ€ìš©ëŸ‰ íŒŒì¼ ë³µì‚¬ë¥¼ ìœ„í•´ ë°°ì¹˜ ì²˜ë¦¬
        find "out-chunk-$i" -type f -name "*.html" -exec cp {} out/ \; 2>/dev/null
        find "out-chunk-$i" -type f -name "*.json" -exec cp {} out/ \; 2>/dev/null
        find "out-chunk-$i" -type f -name "*.xml" -exec cp {} out/ \; 2>/dev/null
        find "out-chunk-$i" -type d -exec mkdir -p out/{} \; 2>/dev/null

        # ì™„ë£Œëœ ì²­í¬ ë””ë ‰í† ë¦¬ ì¦‰ì‹œ ì •ë¦¬ (ë””ìŠ¤í¬ ê³µê°„ ì ˆì•½)
        rm -rf "out-chunk-$i"

        echo "  ğŸ’¾ Disk usage after merging chunk $((i+1)):"
        df -h | grep -E "(Filesystem|overlay)"
    fi
done

# ì¤‘ê°„ ì •ë¦¬
echo "ğŸ§¹ Cleaning up temporary files..."
sync
echo 3 > /proc/sys/vm/drop_caches 2>/dev/null || true

echo "ğŸ—ºï¸ Regenerating final sitemap from merged output..."
node scripts/generate-sitemap.js

# ìµœì¢… ì •ë¦¬
echo "ğŸ§¹ Final cleanup..."
rm -rf .next 2>/dev/null || true
rm -rf node_modules/.cache 2>/dev/null || true

echo ""
echo "ğŸ‰ TRUE parallel build complete!"
echo "ğŸ“Š Final output in: ./out"
echo "ğŸ’¾ Final disk usage:"
df -h
